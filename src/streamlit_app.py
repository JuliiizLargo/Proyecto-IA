# src/streamlit_app.py
import os
import streamlit as st
from pathlib import Path
from src.agentes.agente_extraccion import AgenteExtraccion
from src.agentes.agente_analisis import AgenteAnalisis
from src.agentes.agente_respuesta import AgenteRespuesta

# ConfiguraciÃ³n de la pÃ¡gina
st.set_page_config(page_title="ğŸ§  Asistente de Apuntes", layout="wide")
st.title("ğŸ§  Asistente de BÃºsqueda de Apuntes")

# Sidebar para configuraciÃ³n
with st.sidebar:
    st.header("ConfiguraciÃ³n")
    
    # ConfiguraciÃ³n de la API Key
    api_key = st.text_input(
        "ğŸ”‘ Google API Key",
        type="password",
        help="ObtÃ©n tu API key de Google AI Studio: https://aistudio.google.com/"
    )
    
    # ConfiguraciÃ³n de la carpeta de datos
    data_dir = st.text_input("ğŸ“‚ Carpeta con apuntes", value="data/apuntes/")
    
    # ConfiguraciÃ³n de los chunks
    tam_chunk = st.slider(
        "ğŸ“ TamaÃ±o de los chunks (palabras)",
        min_value=100,
        max_value=1000,
        value=300,
        step=50,
        help="TamaÃ±o de los fragmentos en que se dividirÃ¡n los documentos"
    )
    
    # BotÃ³n para indexar
    if st.button("ğŸ”„ Indexar apuntes", use_container_width=True):
        if not api_key:
            st.error("âŒ Por favor, ingresa tu Google API Key")
            st.stop()
            
        if not os.path.exists(data_dir):
            st.error(f"âŒ La carpeta {data_dir} no existe")
            st.stop()
            
        with st.spinner("ğŸ” Extrayendo y creando Ã­ndice..."):
            try:
                extractor = AgenteExtraccion(data_dir)
                chunks_meta = extractor.procesar(tam_chunk)
                
                if not chunks_meta:
                    st.warning("âš ï¸ No se encontraron documentos para indexar")
                    st.stop()
                
                with st.expander("ğŸ“Š EstadÃ­sticas de indexaciÃ³n", expanded=False):
                    st.write(f"ğŸ“„ Documentos procesados: {len(set(c['documento'] for c in chunks_meta))}")
                    st.write(f"ğŸ§© Chunks creados: {len(chunks_meta)}")
                    
                    # Mostrar documentos indexados
                    docs = sorted(set(c['documento'] for c in chunks_meta))
                    st.write("ğŸ“‹ Documentos indexados:")
                    for doc in docs:
                        st.write(f"  - {doc}")
                
                analisis = AgenteAnalisis()
                analisis.indexar_chunks(chunks_meta)
                st.session_state["analisis"] = analisis
                st.session_state["chunks_meta"] = chunks_meta
                st.success("âœ… Indexado completado")
                
            except Exception as e:
                st.error(f"âŒ Error al indexar: {str(e)}")
                st.exception(e)  # Muestra el traceback completo

# Ãrea principal de bÃºsqueda
st.header("ğŸ” Buscar en los apuntes")

# Mostrar estado actual
if "analisis" not in st.session_state:
    st.warning("âš ï¸ Por favor, indexa los apuntes primero usando el panel lateral")
    st.stop()

# Campo de bÃºsqueda
pregunta = st.text_input(
    "Escribe tu pregunta:",
    placeholder="Ej: Â¿QuÃ© son las redes neuronales?",
    help="Escribe tu pregunta sobre el contenido de los apuntes"
)

# BotÃ³n de bÃºsqueda
if st.button("ğŸ” Buscar", type="primary") and pregunta:
    with st.spinner("ğŸ¤” Procesando tu pregunta..."):
        try:
            analisis = st.session_state.get("analisis")
            fragmentos = analisis.buscar_similares(pregunta, top_k=4)
            
            if not fragmentos:
                st.warning("No se encontraron fragmentos relevantes")
                st.stop()
                
            # Mostrar respuesta
            with st.container():
                st.subheader("ğŸ’¡ Respuesta")
                with st.spinner("Generando respuesta..."):
                    sr = AgenteRespuesta(api_key)
                    respuesta = sr.generar_respuesta(pregunta, fragmentos)
                    st.markdown(f"{respuesta}")
            
            # Mostrar fragmentos
            with st.expander("ğŸ“š Ver fragmentos usados", expanded=False):
                for f in fragmentos:
                    st.markdown(f"### ğŸ“„ {f['documento']} (Chunk {f['chunk_id'] + 1})")
                    st.markdown(f"```\n{f['texto']}\n```")
                    st.write("---")
                    
        except Exception as e:
            st.error(f"âŒ Error al buscar: {str(e)}")

# Footer
st.markdown("---")
st.caption("ğŸ§  Asistente de Apuntes - Procesamiento de lenguaje natural con Gemini")
