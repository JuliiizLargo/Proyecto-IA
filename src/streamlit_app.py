# src/streamlit_app.py
import os
import streamlit as st
from pathlib import Path
from dotenv import load_dotenv
from src.langchain_orquestador import LangChainOrquestador

load_dotenv()

# ConfiguraciÃ³n de la pÃ¡gina
st.set_page_config(page_title="ğŸ§  Asistente de Apuntes", layout="wide")
st.title("ğŸ§  Asistente de BÃºsqueda de Apuntes")

# Sidebar para configuraciÃ³n
with st.sidebar:
    st.header("ConfiguraciÃ³n")
    
    # ConfiguraciÃ³n de la API Key
    api_key = st.text_input(
        "ğŸ”‘ Google API Key",
        type="password",
        help="ObtÃ©n tu API key de Google AI Studio: https://aistudio.google.com/"
    )
    
    # ConfiguraciÃ³n de la carpeta de datos
    data_dir = st.text_input("ğŸ“‚ Carpeta con apuntes", value="data/apuntes/")
    
    # ConfiguraciÃ³n de los chunks
    tam_chunk = st.slider(
        "ğŸ“ TamaÃ±o de los chunks (palabras)",
        min_value=100,
        max_value=1000,
        value=300,
        step=50,
        help="TamaÃ±o de los fragmentos en que se dividirÃ¡n los documentos"
    )
    
    # Modelo de embeddings
    modelo = st.selectbox(
        "ğŸ¤– Modelo de embeddings",
        ["all-MiniLM-L6-v2", "all-mpnet-base-v2"],
        help="Modelo para generar embeddings semÃ¡nticos"
    )
    
    # BotÃ³n para indexar
    if st.button("ğŸ”„ Indexar apuntes", use_container_width=True):
        if not api_key:
            st.error("âŒ Por favor, ingresa tu Google API Key")
            st.stop()
            
        if not os.path.exists(data_dir):
            st.error(f"âŒ La carpeta {data_dir} no existe")
            st.stop()
            
        with st.spinner("ğŸ” Extrayendo, creando chunks e indexando con LangChain..."):
            try:
                # Crear orquestador con LangChain
                orchestrator = LangChainOrquestador(data_dir, modelo_name=modelo, api_key=api_key)
                chunks_meta = orchestrator.indexar(tam_chunk)
                
                if not chunks_meta:
                    st.warning("âš ï¸ No se encontraron documentos para indexar")
                    st.stop()
                
                with st.expander("ğŸ“Š EstadÃ­sticas de indexaciÃ³n", expanded=False):
                    st.write(f"ğŸ“„ Documentos procesados: {len(set(c['documento'] for c in chunks_meta))}")
                    st.write(f"ğŸ§© Chunks creados: {len(chunks_meta)}")
                    
                    # Mostrar documentos indexados
                    docs = sorted(set(c['documento'] for c in chunks_meta))
                    st.write("ğŸ“‹ Documentos indexados:")
                    for doc in docs:
                        st.write(f"  - {doc}")
                
                # Guardar orquestador en sesiÃ³n
                st.session_state["orchestrator"] = orchestrator
                st.success("âœ… Indexado completado con LangChainOrquestador")
                
            except Exception as e:
                st.error(f"âŒ Error al indexar: {str(e)}")
                st.exception(e)  # Muestra el traceback completo

# Ãrea principal de bÃºsqueda
st.header("ğŸ” Buscar en los apuntes")

# Mostrar estado actual
if "orchestrator" not in st.session_state:
    st.warning("âš ï¸ Por favor, indexa los apuntes primero usando el panel lateral")
    st.stop()

# Campo de bÃºsqueda
pregunta = st.text_input(
    "Escribe tu pregunta:",
    placeholder="Ej: Â¿QuÃ© son las redes neuronales?",
    help="Escribe tu pregunta sobre el contenido de los apuntes"
)

# BotÃ³n de bÃºsqueda
if st.button("ğŸ” Buscar", type="primary") and pregunta:
    with st.spinner("ğŸ¤” Procesando tu pregunta con LangChainOrquestador..."):
        try:
            orchestrator = st.session_state.get("orchestrator")
            
            # Usar el orquestador para consultar
            respuesta = orchestrator.consultar(pregunta, top_k=4)
            
            # Mostrar respuesta
            with st.container():
                st.subheader("ğŸ’¡ Respuesta")
                st.markdown(f"{respuesta}")
            
            # Mostrar fragmentos usados (desde el store del orquestador)
            with st.expander("ğŸ“š Ver fragmentos usados", expanded=False):
                fragmentos = orchestrator.search_tool._run(pregunta, top_k=4)
                import json
                fragmentos_list = json.loads(fragmentos)
                for f in fragmentos_list:
                    st.markdown(f"### ğŸ“„ {f['documento']} (Chunk {f['chunk_id'] + 1})")
                    st.markdown(f"```\n{f['texto']}\n```")
                    st.write(f"Similitud: {f['score']:.2%}")
                    st.write("---")
                    
        except Exception as e:
            st.error(f"âŒ Error al buscar: {str(e)}")

# Footer
st.markdown("---")
st.caption("ğŸ§  Asistente de Apuntes - Procesamiento de lenguaje natural con Gemini")
